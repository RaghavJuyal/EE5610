{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import pandas as pd\n",
    "import os\n",
    "from shutil import copyfile\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "csv_file_path = 'C:/Users/rjuya/OneDrive/Desktop/github stuff/EE5610/Project/Data/CXR8/CXR8/Data_Entry_2017_v2020.csv'\n",
    "csv_data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Read train and test indices from text files\n",
    "train_indices_file = 'C:/Users/rjuya/OneDrive/Desktop/github stuff/EE5610/Project/Data/CXR8/CXR8/train_val_list.txt'\n",
    "test_indices_file = 'C:/Users/rjuya/OneDrive/Desktop/github stuff/EE5610/Project/Data/CXR8/CXR8/test_list.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_indices_file, 'r') as file:\n",
    "    train_indices = file.read().splitlines()\n",
    "\n",
    "with open(test_indices_file, 'r') as file:\n",
    "    test_indices = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_class(label):\n",
    "    return label.split('|')[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping image filenames to their labels from the CSV file\n",
    "image_label_map = {}\n",
    "for index, row in csv_data.iterrows():\n",
    "    image_index = row['Image Index']\n",
    "    finding_label = row['Finding Labels']\n",
    "    image_label_map[image_index] = extract_first_class(finding_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_from_tar(tar_filenames, indices):\n",
    "    total_images = len(indices)\n",
    "    extracted_images = {}\n",
    "    images_extracted = 0\n",
    "    percent = 0\n",
    "\n",
    "    for tar_filename in tar_filenames:\n",
    "        with tarfile.open(tar_filename, 'r') as tar:\n",
    "            for member in tar.getmembers():\n",
    "                if member.isfile() and member.name.split('/')[-1] in indices:\n",
    "                    if 'images/' in member.name:  # Considering 'images' as the folder name within tar\n",
    "                        img = tar.extractfile(member)\n",
    "                        img_data = img.read()\n",
    "                        extracted_images[member.name.split('/')[-1]] = img_data\n",
    "                        images_extracted += 1\n",
    "\n",
    "                        # Calculate percentage completion and display progress every 5%\n",
    "                        current_percent = int((images_extracted / total_images) * 100)\n",
    "                        if current_percent >= percent + 5:\n",
    "                            percent = current_percent\n",
    "                            print(f\"{percent}% of images extracted\")\n",
    "\n",
    "    return extracted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5% of images extracted\n",
      "10% of images extracted\n",
      "15% of images extracted\n",
      "20% of images extracted\n",
      "25% of images extracted\n",
      "30% of images extracted\n",
      "35% of images extracted\n",
      "40% of images extracted\n",
      "45% of images extracted\n",
      "50% of images extracted\n",
      "55% of images extracted\n",
      "60% of images extracted\n",
      "65% of images extracted\n",
      "70% of images extracted\n",
      "75% of images extracted\n",
      "80% of images extracted\n",
      "85% of images extracted\n",
      "90% of images extracted\n",
      "95% of images extracted\n",
      "100% of images extracted\n",
      "5% of images extracted\n",
      "10% of images extracted\n",
      "15% of images extracted\n",
      "20% of images extracted\n",
      "25% of images extracted\n",
      "30% of images extracted\n",
      "35% of images extracted\n",
      "40% of images extracted\n",
      "45% of images extracted\n",
      "50% of images extracted\n",
      "55% of images extracted\n",
      "60% of images extracted\n",
      "65% of images extracted\n",
      "70% of images extracted\n",
      "75% of images extracted\n",
      "80% of images extracted\n",
      "85% of images extracted\n",
      "90% of images extracted\n",
      "95% of images extracted\n",
      "100% of images extracted\n"
     ]
    }
   ],
   "source": [
    "# List of paths to all the tar files\n",
    "tar_files = ['C:/Users/rjuya/OneDrive/Desktop/github stuff/EE5610/Project/Data/CXR8/CXR8/images/images_001.tar.gz',\n",
    "             'C:/Users/rjuya/OneDrive/Desktop/github stuff/EE5610/Project/Data/CXR8/CXR8/images/images_002.tar.gz',\n",
    "             'C:/Users/rjuya/OneDrive/Desktop/github stuff/EE5610/Project/Data/CXR8/CXR8/images/images_003.tar.gz',\n",
    "             'C:/Users/rjuya/OneDrive/Desktop/github stuff/EE5610/Project/Data/CXR8/CXR8/images/images_004.tar.gz',\n",
    "             'C:/Users/rjuya/OneDrive/Desktop/github stuff/EE5610/Project/Data/CXR8/CXR8/images/images_005.tar.gz',\n",
    "             'C:/Users/rjuya/OneDrive/Desktop/github stuff/EE5610/Project/Data/CXR8/CXR8/images/images_006.tar.gz',\n",
    "             'C:/Users/rjuya/OneDrive/Desktop/github stuff/EE5610/Project/Data/CXR8/CXR8/images/images_007.tar.gz',\n",
    "             'C:/Users/rjuya/OneDrive/Desktop/github stuff/EE5610/Project/Data/CXR8/CXR8/images/images_008.tar.gz',\n",
    "             'C:/Users/rjuya/OneDrive/Desktop/github stuff/EE5610/Project/Data/CXR8/CXR8/images/images_009.tar.gz',\n",
    "             'C:/Users/rjuya/OneDrive/Desktop/github stuff/EE5610/Project/Data/CXR8/CXR8/images/images_010.tar.gz',\n",
    "             'C:/Users/rjuya/OneDrive/Desktop/github stuff/EE5610/Project/Data/CXR8/CXR8/images/images_011.tar.gz',\n",
    "             'C:/Users/rjuya/OneDrive/Desktop/github stuff/EE5610/Project/Data/CXR8/CXR8/images/images_012.tar.gz']  # Include paths to all 12 tar files\n",
    "\n",
    "# Extract train and test images from all tar files\n",
    "train_images = extract_images_from_tar(tar_files, train_indices)\n",
    "test_images = extract_images_from_tar(tar_files, test_indices)\n",
    "\n",
    "# Create train and test folders to organize extracted images\n",
    "train_folder = 'C:/Users/rjuya/OneDrive/Desktop/github stuff/EE5610/Project/Data/dataset_2/train'\n",
    "test_folder = 'C:/Users/rjuya/OneDrive/Desktop/github stuff/EE5610/Project/Data/dataset_2/test'\n",
    "\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename, img_data in train_images.items():\n",
    "    label = image_label_map[filename]\n",
    "    class_folder = os.path.join(train_folder, label)\n",
    "    os.makedirs(class_folder, exist_ok=True)\n",
    "    with open(os.path.join(class_folder, filename), 'wb') as file:\n",
    "        file.write(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename, img_data in test_images.items():\n",
    "    label = image_label_map[filename]\n",
    "    class_folder = os.path.join(test_folder, label)\n",
    "    os.makedirs(class_folder, exist_ok=True)\n",
    "    with open(os.path.join(class_folder, filename), 'wb') as file:\n",
    "        file.write(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define transforms if needed\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    # Add more transformations as needed\n",
    "])\n",
    "\n",
    "# Create ImageFolder datasets for train and test\n",
    "train_dataset = datasets.ImageFolder(root=train_folder, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_folder, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
